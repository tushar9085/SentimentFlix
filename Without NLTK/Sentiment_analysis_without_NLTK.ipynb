{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Cleaning Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/attreyabhatt/Sentiment-Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all libraries\n",
    "import string\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Stop Words === The words dont create any emotions\n",
    "stop_words = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\",\n",
    "              \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\",\n",
    "              \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\",\n",
    "              \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\",\n",
    "              \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\",\n",
    "              \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\",\n",
    "              \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\",\n",
    "              \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\",\n",
    "              \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\",\n",
    "              \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the string file\n",
    "text = open('read.txt',encoding='utf-8').read()\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning The TExt File\n",
    "#Convert into lower case\n",
    "\n",
    "lower_text = text.lower()\n",
    "#print(lower_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning The TExt File\n",
    "#Remove all the punctuations\n",
    "\n",
    "cleaned_text = lower_text.translate(str.maketrans('','',string.punctuation))\n",
    "#print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization - split all words\n",
    "\n",
    "tokenized_text = cleaned_text.split()\n",
    "#print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Stop Words\n",
    "\n",
    "final_text = []\n",
    "\n",
    "for word in tokenized_text:\n",
    "    if word not in stop_words:\n",
    "        final_text.append(word)\n",
    "\n",
    "#print(final_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Algorithm Part\n",
    "\n",
    " NLP Emotion Algorithm\n",
    " 1) Check if the word in the final word list is also present in emotion.txt\n",
    "  - open the emotion file\n",
    "  - Loop through each line and clear it\n",
    "  - Extract the word and emotion using split\n",
    "\n",
    " 2) If word is present -> Add the emotion to emotion_list\n",
    " 3) Finally count each emotion in the emotion list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the emotion file\n",
    "#Stripping it\n",
    "#Removing extra space, comma,quotation\n",
    "\n",
    "emotion_list = []\n",
    "\n",
    "with open('emotions.txt','r') as file:\n",
    "    #STEP 1\n",
    "    for line in file:\n",
    "        clear_line = line.replace(\"\\n\",'').replace(\",\",'').replace(\"'\",'').strip()\n",
    "        word, emotion = clear_line.split(':')\n",
    "\n",
    "\n",
    "        #STEP 2\n",
    "        if word in final_text:\n",
    "            emotion_list.append(emotion)\n",
    "\n",
    "#print(emotion_list)\n",
    "        \n",
    "emotion_list_counter = Counter(emotion_list)\n",
    "print(emotion_list_counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRAPH\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(emotion_list_counter.keys(),emotion_list_counter.values())\n",
    "fig.autofmt_xdate()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82ad8a63b16339052b1b1e02f4db6cc66764784dbdd55e039ebdd7bf9834d243"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
